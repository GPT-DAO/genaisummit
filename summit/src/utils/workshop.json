[
  {
    "name": "amazon",
    "image": "amazon.png",
    "url": "https://www.amazon.com/",
    "topic": "Build an advanced Retrieval Augmented Generation (RAG) assistant with Amazon Bedrock",
    "description": "This session will guide you through building an advanced generative AI assistant utilizing an advanced Retrieval Augmented Generation (RAG) technique powered by Anthropic Claude 3 on Amazon Bedrock. We will explore how to use Knowledge Bases for Amazon Bedrock for storing, and searching embeddings and how to use Agents for Amazon Bedrock to execute the tasks involved in this process. You will learn how to save time and resources by implementing an efficient and scalable system while ensuring data security throughout the process."
  },
  {
    "name": "sambanova",
    "image": "samba.png",
    "url": "https://www.sambanova.ai/",
    "topic": "Llama3 at its FASTEST!",
    "description": "Join us for a workshop to try out LLama3 at its FASTEST. Explore the capabilities of SambaNova's latest offering, Samba-1 Turbo."
  },
  {
    "name": "ibm",
    "image": "IBM2.png",
    "url": "https://www.ibm.com/",
    "topic": "Scale AI for Your Business: Overview of Watsonx and Common AI Use Cases",
    "description": ""
  },
  {
    "name": "nvidia",
    "image": "nvidia.png",
    "url": "https://www.nvidia.com/",
    "topic": "Hands-on With NVIDIA NIM Inference Microservices",
    "description": "In this hands-on workshop you'll build your own RAG enabled AI chatbot using NVIDIA NIM, a collection of accelerated inference microservices for the latest AI foundation models. You’ll be guided in completing the end-to-end development lifecycle beginning with application prototyping using the NVIDIA API catalog and ending with production deployment using self-hosted NIM inference microservices running on NVIDIA DGX. We will cover essential RAG enabled chatbot architecture, tools, and workflow as well as production deployment best practices including inference optimization technology and techniques. You’ll leave with first-hand experience and understanding of the end-to-end development lifecycle for enterprise generative AI applications including how to deploy models at scale for secure, performance optimized inference anywhere."
  },
  {
    "name": "deepchecks",
    "image": "deepchecks.png",
    "url": "https://deepchecks.com/",
    "topic": "Hands on LLM Evaluation Workshop",
    "description": "In this workshop, meant for LLM practitioners, participants will have a hands-on experience setting up an LLM Evaluation mechanism. The session will be based on Deepchecks' LLM Evaluation framework, and will include configuring LLM properties, comparing the performance of multiple versions of the same app, and configuring the system's decision making process by aggregating properties, similarity assessments and LLM-judge outputs."
  },
  {
    "name": "otter",
    "image": "otter.png",
    "url": "https://otter.ai/",
    "topic": "How to Use Otter.AI to Enpower GenAI Productivity at Work",
    "description": ""
  },
  {
    "name": "zilliz",
    "image": "zilliz.png",
    "url": "https://zilliz.com/",
    "topic": "Upgrade Your GenAI Applications with Multimodal RAG",
    "description": ""
  },
  {
    "name": "zuora",
    "image": "zuora.png",
    "url": "https://www.zuora.com/sulutions/accurately-capture-meter-usage",
    "topic": "How to Monetize GenAI with Zuora",
    "description": ""
  }
]
